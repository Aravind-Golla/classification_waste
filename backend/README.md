# Waste Classifier Backend API

Flask-based REST API for AI-powered waste classification using TensorFlow/Keras.

## Features

‚úÖ **In-Memory Processing** - No files saved to disk or cloud storage  
‚úÖ **Fast & Secure** - All image processing happens in RAM  
‚úÖ **Simple Deployment** - No external storage dependencies (S3, etc.)  
‚úÖ **CORS Enabled** - Works with frontend from any origin  
‚úÖ **Mock Mode** - Returns mock predictions when model not loaded (for testing)  

## API Endpoints

### `GET /api/health`
Check backend health and model status.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "classes_loaded": 12,
  "processing": "in-memory"
}
```

### `GET /api/classes`
Get list of waste classification categories.

**Response:**
```json
{
  "classes": ["battery", "biological", "brown-glass", ...],
  "total": 12
}
```

### `POST /api/predict`
Classify uploaded waste image (in-memory processing).

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Body: Form data with `image` field containing the image file

**Example (curl):**
```bash
curl -X POST http://localhost:5000/api/predict \
  -F "image=@waste_photo.jpg"
```

**Response:**
```json
{
  "predicted_class": "plastic",
  "confidence": 0.92,
  "confidence_percentage": 92.5,
  "category": "Plastic",
  "degradable": false,
  "risk_level": "low",
  "disposal_tip": "Check the recycling number. Clean and dry before recycling."
}
```

## Installation

### 1. Install Dependencies

```bash
cd backend
pip install -r ../requirements.txt
```

### 2. Setup Model Files

Ensure these files exist in the `backend/` directory:
- `waste_classifier_mobilenet.h5` - Trained Keras model
- `class_names.json` - Class index to name mapping

### 3. Run the Server

```bash
python app.py
```

The API will be available at `http://localhost:5000`

**Note:** The backend uses environment variables for configuration:
- `PORT` (default: 5000) - Server port
- `FLASK_DEBUG` (default: False) - Debug mode

For PM2 deployment, these are configured in `ecosystem.config.js`

## In-Memory Processing

This backend uses **100% in-memory processing**:

1. **Image Upload** ‚Üí Read directly into memory (no temp files)
2. **Preprocessing** ‚Üí PIL processes bytes in RAM
3. **Prediction** ‚Üí TensorFlow/Keras runs inference in memory
4. **Response** ‚Üí JSON returned immediately

### Benefits:

- **üöÄ Faster**: No disk I/O overhead
- **üîí More Secure**: Images never touch filesystem
- **üí∞ Cost Effective**: No cloud storage costs (S3, etc.)
- **üéØ Simpler**: Fewer dependencies and configuration
- **‚ôªÔ∏è Cleaner**: Automatic cleanup (garbage collection)

### Memory Usage:

- Each request typically uses < 50MB RAM
- Images are discarded after prediction
- Safe for concurrent requests

## Model Information

The backend uses MobileNet-based architecture for efficient inference:

- **Input Size**: 224x224 pixels (RGB)
- **Preprocessing**: Normalization (0-1 scale)
- **Output**: 12 waste categories
- **Inference Time**: ~100-500ms (CPU)

## Development

### Mock Mode

If the model fails to load, the API automatically returns mock predictions:

```json
{
  "predicted_class": "plastic",
  "confidence": 0.85,
  ...
}
```

This allows frontend development without a working ML model.

### Debug Mode

Enable debug mode by setting environment variable:

```bash
FLASK_DEBUG=True python app.py
```

**‚ö†Ô∏è Never use debug mode in production!**

For PM2, configure in `ecosystem.config.js`.

## Troubleshooting

### Model Not Loading

**Error:** `ValueError: numpy.dtype size changed`

**Solution:**
```bash
pip install --upgrade numpy tensorflow
```

### CORS Issues

The backend has CORS enabled for all origins. If you still face issues:

1. Check that flask-cors is installed: `pip install flask-cors`
2. Restart the backend after any changes

### Port Already in Use

Change the port using environment variable:
```bash
PORT=5001 python app.py
```

## Production Deployment

### Recommended Setup:

```bash
# Use Gunicorn for production
pip install gunicorn

# Run with multiple workers
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

### Environment Variables:

```env
FLASK_DEBUG=False
PORT=5000
```

### Performance Tips:

- Use **4-8 workers** for CPU-bound inference
- Enable **HTTP/2** for faster uploads
- Consider **GPU** for high traffic (TensorFlow GPU support)
- Add **load balancer** for scaling horizontally

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ
‚îÇ  (React App)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP POST /api/predict
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Flask API (app.py)        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Image Upload       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (multipart/form)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ             ‚Üì                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  In-Memory Buffer   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (io.BytesIO)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ             ‚Üì                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  PIL Image Processing‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (RGB, Resize)      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ             ‚Üì                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  TensorFlow/Keras   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (MobileNet Model)  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ             ‚Üì                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Classification     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Results + Tips     ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì JSON Response
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ
‚îÇ (Results View)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Technology Stack

- **Flask 3.0** - Web framework
- **TensorFlow 2.15** - ML inference
- **PIL/Pillow** - Image processing
- **NumPy** - Array operations
- **Flask-CORS** - Cross-origin support

## License

Part of the Waste Classifier project.
